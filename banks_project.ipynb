{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1a2bad-9a26-4363-bb50-1974a6353b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted DataFrame (top 10):\n",
      "                                      Name  MC_USD_Billion\n",
      "0                           JPMorgan Chase          432.92\n",
      "1                          Bank of America          231.52\n",
      "2  Industrial and Commercial Bank of China          194.56\n",
      "3               Agricultural Bank of China          160.68\n",
      "4                                HDFC Bank          157.91\n",
      "5                              Wells Fargo          155.87\n",
      "6                        HSBC Holdings PLC          148.90\n",
      "7                           Morgan Stanley          140.83\n",
      "8                  China Construction Bank          139.82\n",
      "9                            Bank of China          136.81\n",
      "\n",
      "Transformed DataFrame:\n",
      "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
      "0                           JPMorgan Chase          432.92          346.34   \n",
      "1                          Bank of America          231.52          185.22   \n",
      "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
      "3               Agricultural Bank of China          160.68          128.54   \n",
      "4                                HDFC Bank          157.91          126.33   \n",
      "5                              Wells Fargo          155.87          124.70   \n",
      "6                        HSBC Holdings PLC          148.90          119.12   \n",
      "7                           Morgan Stanley          140.83          112.66   \n",
      "8                  China Construction Bank          139.82          111.86   \n",
      "9                            Bank of China          136.81          109.45   \n",
      "\n",
      "   MC_EUR_Billion  MC_INR_Billion  \n",
      "0          402.62        35910.71  \n",
      "1          215.31        19204.58  \n",
      "2          180.94        16138.75  \n",
      "3          149.43        13328.41  \n",
      "4          146.86        13098.63  \n",
      "5          144.96        12929.42  \n",
      "6          138.48        12351.26  \n",
      "7          130.97        11681.85  \n",
      "8          130.03        11598.07  \n",
      "9          127.23        11348.39  \n",
      "\n",
      "Saved CSV to: ./Largest_banks_data.csv\n",
      "Loaded table 'Largest_banks' into database 'Banks.db'\n",
      "\n",
      "QUERY: SELECT * FROM Largest_banks;\n",
      "('JPMorgan Chase', 432.92, 346.34, 402.62, 35910.71)\n",
      "('Bank of America', 231.52, 185.22, 215.31, 19204.58)\n",
      "('Industrial and Commercial Bank of China', 194.56, 155.65, 180.94, 16138.75)\n",
      "('Agricultural Bank of China', 160.68, 128.54, 149.43, 13328.41)\n",
      "('HDFC Bank', 157.91, 126.33, 146.86, 13098.63)\n",
      "('Wells Fargo', 155.87, 124.7, 144.96, 12929.42)\n",
      "('HSBC Holdings PLC', 148.9, 119.12, 138.48, 12351.26)\n",
      "('Morgan Stanley', 140.83, 112.66, 130.97, 11681.85)\n",
      "('China Construction Bank', 139.82, 111.86, 130.03, 11598.07)\n",
      "('Bank of China', 136.81, 109.45, 127.23, 11348.39)\n",
      "\n",
      "QUERY: SELECT AVG(MC_GBP_Billion) FROM Largest_banks;\n",
      "(151.987,)\n",
      "\n",
      "QUERY: SELECT Name FROM Largest_banks LIMIT 5;\n",
      "('JPMorgan Chase',)\n",
      "('Bank of America',)\n",
      "('Industrial and Commercial Bank of China',)\n",
      "('Agricultural Bank of China',)\n",
      "('HDFC Bank',)\n",
      "\n",
      "--- LOG FILE CONTENTS ---\n",
      "[2025-12-25 09:00:58] Preliminaries complete. Starting ETL process.\n",
      "[2025-12-25 09:01:03] Data extraction complete.\n",
      "[2025-12-25 09:01:04] Data transformation complete.\n",
      "[2025-12-25 09:01:04] Data saved to CSV file.\n",
      "[2025-12-25 09:01:04] Data loaded to Database as a table.\n",
      "[2025-12-25 09:01:04] Running query: SELECT * FROM Largest_banks;\n",
      "[2025-12-25 09:01:04] Running query: SELECT AVG(MC_GBP_Billion) FROM Largest_banks;\n",
      "[2025-12-25 09:01:04] Running query: SELECT Name FROM Largest_banks LIMIT 5;\n",
      "[2025-12-25 09:01:04] Process Complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# banks_project.py\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG (per project spec)\n",
    "# -------------------------\n",
    "DATA_URL = \"https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
    "EXCHANGE_RATE_CSV = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv\"\n",
    "\n",
    "TABLE_ATTRS_EXTRACT = [\"Name\", \"MC_USD_Billion\"]\n",
    "TABLE_ATTRS_FINAL = [\"Name\", \"MC_USD_Billion\", \"MC_GBP_Billion\", \"MC_EUR_Billion\", \"MC_INR_Billion\"]\n",
    "\n",
    "OUTPUT_CSV = \"./Largest_banks_data.csv\"\n",
    "DB_NAME = \"Banks.db\"\n",
    "TABLE_NAME = \"Largest_banks\"\n",
    "LOG_FILE = \"code_log.txt\"\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# TASK 1: Logging\n",
    "# -------------------------\n",
    "def log_progress(message: str, log_file: str = LOG_FILE) -> None:\n",
    "    \"\"\"\n",
    "    Appends a timestamped message to the log file.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[{timestamp}] {message}\\n\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# TASK 2: Extraction\n",
    "# -------------------------\n",
    "def extract(url: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts the 'By market capitalization' table from the provided URL and returns\n",
    "    a DataFrame containing: Name, MC_USD_Billion (top 10 rows).\n",
    "    \"\"\"\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the heading span with id=\"By_market_capitalization\"\n",
    "    heading = soup.find(id=\"By_market_capitalization\")\n",
    "    if heading is None:\n",
    "        raise ValueError(\"Could not find the 'By market capitalization' section (id=By_market_capitalization).\")\n",
    "\n",
    "    # The target table is typically the first wikitable after the heading\n",
    "    table = heading.find_parent([\"h2\", \"h3\"]).find_next(\"table\", class_=\"wikitable\")\n",
    "    if table is None:\n",
    "        raise ValueError(\"Could not find the wikitable following the 'By market capitalization' heading.\")\n",
    "\n",
    "    # Parse table rows\n",
    "    rows = table.find_all(\"tr\")\n",
    "    data = []\n",
    "\n",
    "    for r in rows[1:]:  # skip header\n",
    "        cols = r.find_all([\"th\", \"td\"])\n",
    "        if len(cols) < 3:\n",
    "            continue\n",
    "\n",
    "        # Typical columns (as of the archived page):\n",
    "        # 0: Rank, 1: Bank name, 2: Market cap (US$ billion)\n",
    "        name = cols[1].get_text(strip=True)\n",
    "        mc_text = cols[2].get_text(strip=True).replace(\",\", \"\")\n",
    "        try:\n",
    "            mc_usd = float(mc_text)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        data.append([name, mc_usd])\n",
    "\n",
    "        if len(data) == 10:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(data, columns=TABLE_ATTRS_EXTRACT)\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# TASK 3: Transformation\n",
    "# -------------------------\n",
    "def transform(df: pd.DataFrame, exchange_rate_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds MC_GBP_Billion, MC_EUR_Billion, MC_INR_Billion using exchange rates from CSV,\n",
    "    rounded to 2 decimals.\n",
    "    \"\"\"\n",
    "    rates_df = pd.read_csv(exchange_rate_csv)\n",
    "\n",
    "    # Expecting columns like: Currency, Rate\n",
    "    # Build a dict: {\"GBP\": rate, \"EUR\": rate, \"INR\": rate}\n",
    "    rate_map = dict(zip(rates_df[\"Currency\"], rates_df[\"Rate\"]))\n",
    "\n",
    "    for cur in [\"GBP\", \"EUR\", \"INR\"]:\n",
    "        if cur not in rate_map:\n",
    "            raise ValueError(f\"Exchange rate for {cur} not found in exchange rate CSV.\")\n",
    "\n",
    "    df_out = df.copy()\n",
    "    df_out[\"MC_GBP_Billion\"] = (df_out[\"MC_USD_Billion\"] * rate_map[\"GBP\"]).round(2)\n",
    "    df_out[\"MC_EUR_Billion\"] = (df_out[\"MC_USD_Billion\"] * rate_map[\"EUR\"]).round(2)\n",
    "    df_out[\"MC_INR_Billion\"] = (df_out[\"MC_USD_Billion\"] * rate_map[\"INR\"]).round(2)\n",
    "\n",
    "    return df_out[TABLE_ATTRS_FINAL]\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# TASK 4: Load to CSV\n",
    "# -------------------------\n",
    "def load_to_csv(df: pd.DataFrame, output_path: str) -> None:\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# TASK 5: Load to DB\n",
    "# -------------------------\n",
    "def load_to_db(df: pd.DataFrame, db_name: str, table_name: str) -> None:\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    try:\n",
    "        df.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# TASK 6: Run queries\n",
    "# -------------------------\n",
    "def run_queries(db_name: str, table_name: str) -> None:\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        queries = [\n",
    "            f\"SELECT * FROM {table_name};\",\n",
    "            f\"SELECT AVG(MC_GBP_Billion) FROM {table_name};\",\n",
    "            f\"SELECT Name FROM {table_name} LIMIT 5;\"\n",
    "        ]\n",
    "\n",
    "        for q in queries:\n",
    "            log_progress(f\"Running query: {q}\")\n",
    "            print(\"\\nQUERY:\", q)\n",
    "            cursor.execute(q)\n",
    "            results = cursor.fetchall()\n",
    "            for row in results:\n",
    "                print(row)\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# TASK 1â€“7: Orchestration\n",
    "# -------------------------\n",
    "def main():\n",
    "    log_progress(\"Preliminaries complete. Starting ETL process.\")\n",
    "\n",
    "    # Extract\n",
    "    df_extracted = extract(DATA_URL)\n",
    "    log_progress(\"Data extraction complete.\")\n",
    "    print(\"Extracted DataFrame (top 10):\")\n",
    "    print(df_extracted)\n",
    "\n",
    "    # Transform\n",
    "    df_transformed = transform(df_extracted, EXCHANGE_RATE_CSV)\n",
    "    log_progress(\"Data transformation complete.\")\n",
    "    print(\"\\nTransformed DataFrame:\")\n",
    "    print(df_transformed)\n",
    "\n",
    "    # Load to CSV\n",
    "    load_to_csv(df_transformed, OUTPUT_CSV)\n",
    "    log_progress(\"Data saved to CSV file.\")\n",
    "    print(f\"\\nSaved CSV to: {OUTPUT_CSV}\")\n",
    "\n",
    "    # Load to DB\n",
    "    load_to_db(df_transformed, DB_NAME, TABLE_NAME)\n",
    "    log_progress(\"Data loaded to Database as a table.\")\n",
    "    print(f\"Loaded table '{TABLE_NAME}' into database '{DB_NAME}'\")\n",
    "\n",
    "    # Queries\n",
    "    run_queries(DB_NAME, TABLE_NAME)\n",
    "\n",
    "    log_progress(\"Process Complete.\")\n",
    "\n",
    "    # Task 7: Show log contents (verify log entries)\n",
    "    print(\"\\n--- LOG FILE CONTENTS ---\")\n",
    "    with open(LOG_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        print(f.read())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57d1ee-d5de-4d46-8a3a-a2b8cfb89255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
